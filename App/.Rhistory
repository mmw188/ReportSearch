grid.sample <- rep(1:nr, ceiling(iters*batch/nr))[c(1:(batch*iters))]
rand.sample <- sample(1:nr, batch*iters, replace = TRUE)
master <- c()
for (n in 1:iters){
## 5.1 Obs (for everybody)
if (s.met == 'ADO'){
info.gain <- unlist(mclapply(1:nr,
function(x) calc.collapse.u(p.est$p[[x]], combos, post, bns)))
selection <- sort(-info.gain, index.return = TRUE)$ix
selection <- selection[1:10]
} else if (s.met == 'Random'){
selection <- rand.sample[(n-1)*batch+c(1:batch)]
} else if (s.met == 'Grid'){
selection <- grid.sample[(n-1)*batch+c(1:batch)]
}
## 5.4 Simulate Outcome
outs <- array(NA, dim = 10)
for (ct in 1:batch){
id      <- selection[ct]
outcome <- unlist(lapply(id,
function(x) min(which(runif(1) < p.est$draw[[x]]))))
## 5.5 Update
p.dist <- unlist(p.est$p[id]) + post[, outcome] ##p(x)*p(y|x)
p.dist <- p.dist - logSumExp(p.dist) ##normalize
p.est$p[id] <- list(p.dist)
p.est$count[id] <- p.est$count[id] + 1
outs[ct] <- outcome
p.est$p.bin[id] <- list(unlist(lapply(1:6,
function(x) logSumExp(p.dist[bns == x]))))
}
temp <- p.est[c('Candidate', 'Attribute', 'id', 'mu', 'Value', 'Bin', 'count', 'p.bin')] %>%
mutate(sim.round  = n,
sim.method = s.met,
sim.draw   = 0,
outcome    = 0)
temp$sim.draw[selection] <- 1
temp$outcome[selection] <- outs
master[[n]] <- temp
}
master <- do.call("rbind", master)
master
n<-1
## 5.1 Obs (for everybody)
if (s.met == 'ADO'){
info.gain <- unlist(mclapply(1:nr,
function(x) calc.collapse.u(p.est$p[[x]], combos, post, bns)))
selection <- sort(-info.gain, index.return = TRUE)$ix
selection <- selection[1:10]
} else if (s.met == 'Random'){
selection <- rand.sample[(n-1)*batch+c(1:batch)]
} else if (s.met == 'Grid'){
selection <- grid.sample[(n-1)*batch+c(1:batch)]
}
## 5.4 Simulate Outcome
outs <- array(NA, dim = 10)
for (ct in 1:batch){
id      <- selection[ct]
outcome <- unlist(lapply(id,
function(x) min(which(runif(1) < p.est$draw[[x]]))))
## 5.5 Update
p.dist <- unlist(p.est$p[id]) + post[, outcome] ##p(x)*p(y|x)
p.dist <- p.dist - logSumExp(p.dist) ##normalize
p.est$p[id] <- list(p.dist)
p.est$count[id] <- p.est$count[id] + 1
outs[ct] <- outcome
p.est$p.bin[id] <- list(unlist(lapply(1:6,
function(x) logSumExp(p.dist[bns == x]))))
}
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(parallel)
library(viridis)
source('ado_funs.R')
output.dir <- 'outputs'
input.dir  <- 'inputs'
m.eps      <- .Machine$double.eps
sim.inputs <- readRDS(file.path(input.dir, 'SimulationInputs.RDS'))
## Load previously estimated thresholds of multinomial logistic regression
thresholds <- sim.inputs$thresholds
thresh     <- as.numeric(thresholds$Value)
## Using multinomial logistic regression model, compute probability of ratings 0 to 5 given latent values ranging from -4.5 to 4.5
n.seq <- seq(from = -4.5, to = 4.5, by = .05)
bns <- unlist(lapply(n.seq,
function(x) min(which(x <= c(thresh, Inf)))))
combos <- multi(n.seq, thresholds)
combos[combos == 0] <- m.eps
## Plot the multinomial model
plot.multinomial(combos)
## Convert to log scale to prevent underflow errors
post <- log(combos)
df.sub <- sim.inputs$df.sub
## Generate priors for each attribute
att.list <- unique(df.sub$Attribute)
wt <- .25 ## Note, we convolve informed prior with uniform prior. WT controls weight given to informed prior
p.vec <- data.frame(Attribute = att.list, p = NaN, stringsAsFactors = FALSE)
for (i in att.list){
p.vec$p[p.vec$Attribute == i]     <- gen.prior(post, filter(df.sub, Attribute == i), wt)
p.vec$p.bin[p.vec$Attribute == i] <- bin.probs(p.vec$p[p.vec$Attribute == i], bns)
}
## Plot priors
plot.priors(p.vec, n.seq)
p.est <- sim.inputs$p.est
p.est <- left_join(p.est %>% select(-p), p.vec, by = 'Attribute')
#ado.results <- ado_fun(p.est, combos, post, bns, 'ADO')
rand.results <- ado_fun(p.est, combos, post, bns, 'Random')
rand.results <- run_ado(p.est, combos, post, bns, 'Random')
warnings()
p.est$draw
nr
rows(p.est)
nrowp.est$draw <- lapply(1:nrow(p.est),
function(x) c(exp(thresh - p.est$Value[x])/(1 + exp(thresh - p.est$Value[x])), 1))
p.est$draw <- lapply(1:nrow(p.est),
function(x) c(exp(thresh - p.est$Value[x])/(1 + exp(thresh - p.est$Value[x])), 1))
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(parallel)
library(viridis)
source('ado_funs.R')
output.dir <- 'outputs'
input.dir  <- 'inputs'
m.eps      <- .Machine$double.eps
sim.inputs <- readRDS(file.path(input.dir, 'SimulationInputs.RDS'))
## Load previously estimated thresholds of multinomial logistic regression
thresholds <- sim.inputs$thresholds
thresh     <- as.numeric(thresholds$Value)
## Using multinomial logistic regression model, compute probability of ratings 0 to 5 given latent values ranging from -4.5 to 4.5
n.seq <- seq(from = -4.5, to = 4.5, by = .05)
bns <- unlist(lapply(n.seq,
function(x) min(which(x <= c(thresh, Inf)))))
combos <- multi(n.seq, thresholds)
combos[combos == 0] <- m.eps
## Plot the multinomial model
plot.multinomial(combos)
## Convert to log scale to prevent underflow errors
post <- log(combos)
df.sub <- sim.inputs$df.sub
## Generate priors for each attribute
att.list <- unique(df.sub$Attribute)
wt <- .25 ## Note, we convolve informed prior with uniform prior. WT controls weight given to informed prior
p.vec <- data.frame(Attribute = att.list, p = NaN, stringsAsFactors = FALSE)
for (i in att.list){
p.vec$p[p.vec$Attribute == i]     <- gen.prior(post, filter(df.sub, Attribute == i), wt)
p.vec$p.bin[p.vec$Attribute == i] <- bin.probs(p.vec$p[p.vec$Attribute == i], bns)
}
## Plot priors
plot.priors(p.vec, n.seq)
p.est <- sim.inputs$p.est
p.est <- left_join(p.est %>% select(-p), p.vec, by = 'Attribute')
p.est$draw <- lapply(1:nrow(p.est),
function(x) c(exp(thresh - p.est$Value[x])/(1 + exp(thresh - p.est$Value[x])), 1))
#ado.results <- run_ado(p.est, combos, post, bns, 'ADO')
rand.results <- run_ado(p.est, combos, post, bns, 'Random')
grid.results <- run_ado(p.est, combos, post, bns, 'Grid')
dim(rand.results)
getwd
getwd()
setwd("~/Desktop/RAND_Desktop/NonRAND/ExternalRepo/ADO/src")
saveRDS(list(thresholds = thresholds, df.sub = df.sub, p.est = p.est))
saveRDS(list(thresholds = thresholds, df.sub = df.sub, p.est = p.est), 'SimulationInputs.RDS')
getwd()
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(parallel)
library(viridis)
source('ado_funs.R')
output.dir <- 'outputs'
input.dir  <- 'inputs'
m.eps      <- .Machine$double.eps
sim.inputs <- readRDS(file.path(input.dir, 'SimulationInputs.RDS'))
## Load previously estimated thresholds of multinomial logistic regression
thresholds <- sim.inputs$thresholds
thresh     <- as.numeric(thresholds$Value)
## Using multinomial logistic regression model, compute probability of ratings 0 to 5 given latent values ranging from -4.5 to 4.5
n.seq <- seq(from = -4.5, to = 4.5, by = .05)
bns <- unlist(lapply(n.seq,
function(x) min(which(x <= c(thresh, Inf)))))
combos <- multi(n.seq, thresholds)
combos[combos == 0] <- m.eps
## Plot the multinomial model
plot.multinomial(combos)
## Convert to log scale to prevent underflow errors
post <- log(combos)
df.sub <- sim.inputs$df.sub
## Generate priors for each attribute
att.list <- unique(df.sub$Attribute)
wt <- .25 ## Note, we convolve informed prior with uniform prior. WT controls weight given to informed prior
p.vec <- data.frame(Attribute = att.list, p = NaN, stringsAsFactors = FALSE)
for (i in att.list){
p.vec$p[p.vec$Attribute == i]     <- gen.prior(post, filter(df.sub, Attribute == i), wt)
p.vec$p.bin[p.vec$Attribute == i] <- bin.probs(p.vec$p[p.vec$Attribute == i], bns)
}
## Plot priors
plot.priors(p.vec, n.seq)
p.est <- sim.inputs$p.est
p.est <- left_join(p.est %>% select(-p), p.vec, by = 'Attribute')
#ado.results <- run_ado(p.est, combos, post, bns, 'ADO')
rand.results <- run_ado(p.est, combos, post, bns, 'Random')
View(p.est)
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(parallel)
library(viridis)
source('ado_funs.R')
output.dir <- 'outputs'
input.dir  <- 'inputs'
m.eps      <- .Machine$double.eps
sim.inputs <- readRDS(file.path(input.dir, 'SimulationInputs.RDS'))
## Load previously estimated thresholds of multinomial logistic regression
thresholds <- sim.inputs$thresholds
thresh     <- as.numeric(thresholds$Value)
## Using multinomial logistic regression model, compute probability of ratings 0 to 5 given latent values ranging from -4.5 to 4.5
n.seq <- seq(from = -4.5, to = 4.5, by = .05)
bns <- unlist(lapply(n.seq,
function(x) min(which(x <= c(thresh, Inf)))))
combos <- multi(n.seq, thresholds)
combos[combos == 0] <- m.eps
## Plot the multinomial model
plot.multinomial(combos)
## Convert to log scale to prevent underflow errors
post <- log(combos)
df.sub <- sim.inputs$df.sub
## Generate priors for each attribute
att.list <- unique(df.sub$Attribute)
wt <- .25 ## Note, we convolve informed prior with uniform prior. WT controls weight given to informed prior
p.vec <- data.frame(Attribute = att.list, p = NaN, stringsAsFactors = FALSE)
for (i in att.list){
p.vec$p[p.vec$Attribute == i]     <- gen.prior(post, filter(df.sub, Attribute == i), wt)
p.vec$p.bin[p.vec$Attribute == i] <- bin.probs(p.vec$p[p.vec$Attribute == i], bns)
}
## Plot priors
plot.priors(p.vec, n.seq)
p.est <- sim.inputs$p.est
p.est$draw <- lapply(1:nr,
function(x) c(exp(thresh - p.est$Value[x])/(1 + exp(thresh - p.est$Value[x])), 1))
nr <- nrow(p.est)
p.est <- sim.inputs$p.est
p.est$draw <- lapply(1:nr,
function(x) c(exp(thresh - p.est$Value[x])/(1 + exp(thresh - p.est$Value[x])), 1))
saveRDS(list(thresholds = thresholds, p.est = p.est, df.sub = df.sub), 'SimulationInputs.RDS')
getwd()
View(p.est)
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(parallel)
library(viridis)
source('ado_funs.R')
output.dir <- 'outputs'
input.dir  <- 'inputs'
m.eps      <- .Machine$double.eps
sim.inputs <- readRDS(file.path(input.dir, 'SimulationInputs.RDS'))
## Load previously estimated thresholds of multinomial logistic regression
thresholds <- sim.inputs$thresholds
thresh     <- as.numeric(thresholds$Value)
## Using multinomial logistic regression model, compute probability of ratings 0 to 5 given latent values ranging from -4.5 to 4.5
n.seq <- seq(from = -4.5, to = 4.5, by = .05)
bns <- unlist(lapply(n.seq,
function(x) min(which(x <= c(thresh, Inf)))))
combos <- multi(n.seq, thresholds)
combos[combos == 0] <- m.eps
## Plot the multinomial model
plot.multinomial(combos)
## Convert to log scale to prevent underflow errors
post <- log(combos)
df.sub <- sim.inputs$df.sub
## Generate priors for each attribute
att.list <- unique(df.sub$Attribute)
wt <- .25 ## Note, we convolve informed prior with uniform prior. WT controls weight given to informed prior
p.vec <- data.frame(Attribute = att.list, p = NaN, stringsAsFactors = FALSE)
for (i in att.list){
p.vec$p[p.vec$Attribute == i]     <- gen.prior(post, filter(df.sub, Attribute == i), wt)
p.vec$p.bin[p.vec$Attribute == i] <- bin.probs(p.vec$p[p.vec$Attribute == i], bns)
}
## Plot priors
plot.priors(p.vec, n.seq)
p.est <- sim.inputs$p.est
p.est <- left_join(p.est %>% select(-p), p.vec, by = 'Attribute')
#ado.results <- run_ado(p.est, combos, post, bns, 'ADO')
rand.results <- run_ado(p.est, combos, post, bns, 'Random')
grid.results <- run_ado(p.est, combos, post, bns, 'Grid')
dim(grid.results)
View(head(grid.results))
f1 <- grid.results %>%
mutate(cv = p.bin[Bin])
View(head(f1))
f1 <- grid.results %>%
mutate(cv = p.bin[[Bin]])
f1 <- grid.results %>%
mutate(cv = unlist(p.bin)[Bin])
View(f1)
colnames(f1)
f1 <- grid.results %>%
mutate(correct.val = unlist(p.bin)[Bin]) %>%
group_by(sim.round) %>%
summarise(Prob.Correct = mean(exp(correct.val)))
View(f1)
View(grid.results)
f1 <- filter(grid.results, Candidate == '1', Attribute == 'Attribute A')
View(f1)
f1 <- f1 %>% mutate(cv = unlist(p.bin)[Bin])
View(f1)
View(filter(f1, sim.draw == 1))
f2 <- filter(f1, sim.draw == 1)
View(f2)
f2$p.bin[9]
exp(-0.01099912)
f2$p.bin[1]
f3 <- f2 %>% mutate(fer = ungroup(p.bin)[1])
f3 <- f2 %>% mutate(fer = unlist(p.bin)[1])
f3
f1<- data.frame(do.call(rbind,f3$p.bin))
dim(f1)
Vifew(f1)
View(f1)
master<-grid.results
f1<-master$p.bin %>% bind_cols()
colnames(f1)
colnames(master)
unique(master$Bin)
f2<-data.frame(do.call(rbind,masster$p.bin)
)
f2<-data.frame(do.call(rbind,master$p.bin))
colnames(f2)
master<-grid.results
master <- rbind(master, data.frame(do.call(rbind,masster$p.bin))) %>%
mutate(p_correct = case_when(Bin == 1 ~ X1,
Bin == 2 ~ X2,
Bin == 3 ~ X3,
Bin == 4 ~ X4,
Bin == 5 ~ X5,
Bin == 6 ~ X6))
master <- rbind(master, data.frame(do.call(rbind, master$p.bin))) %>%
mutate(p_correct = case_when(Bin == 1 ~ X1,
Bin == 2 ~ X2,
Bin == 3 ~ X3,
Bin == 4 ~ X4,
Bin == 5 ~ X5,
Bin == 6 ~ X6))
master <- rbind(master, data.frame(do.call(rbind, master$p.bin)))
master <- cbind(master, data.frame(do.call(rbind, master$p.bin))) %>%
mutate(p_correct = case_when(Bin == 1 ~ X1,
Bin == 2 ~ X2,
Bin == 3 ~ X3,
Bin == 4 ~ X4,
Bin == 5 ~ X5,
Bin == 6 ~ X6))
View(master)
master<-grid.results
master <- cbind(master, data.frame(do.call(rbind, master$p.bin))) %>%
mutate(p_correct = case_when(Bin == 1 ~ X1,
Bin == 2 ~ X2,
Bin == 3 ~ X3,
Bin == 4 ~ X4,
Bin == 5 ~ X5,
Bin == 6 ~ X6)) %>%
group_by(sim.round) %>%
summarise(Prob.Correct = mean(exp(correct.val)))
master <- cbind(master, data.frame(do.call(rbind, master$p.bin))) %>%
mutate(p_correct = case_when(Bin == 1 ~ X1,
Bin == 2 ~ X2,
Bin == 3 ~ X3,
Bin == 4 ~ X4,
Bin == 5 ~ X5,
Bin == 6 ~ X6)) %>%
group_by(sim.round) %>%
summarise(Prob.Correct = mean(exp(p_correct)))
plot(master$Prob.Correct)
colnames(master)
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(parallel)
library(viridis)
source('ado_funs.R')
output.dir <- 'outputs'
input.dir  <- 'inputs'
m.eps      <- .Machine$double.eps
sim.inputs <- readRDS(file.path(input.dir, 'SimulationInputs.RDS'))
## Load previously estimated thresholds of multinomial logistic regression
thresholds <- sim.inputs$thresholds
thresh     <- as.numeric(thresholds$Value)
## Using multinomial logistic regression model, compute probability of ratings 0 to 5 given latent values ranging from -4.5 to 4.5
n.seq <- seq(from = -4.5, to = 4.5, by = .05)
bns <- unlist(lapply(n.seq,
function(x) min(which(x <= c(thresh, Inf)))))
combos <- multi(n.seq, thresholds)
combos[combos == 0] <- m.eps
## Plot the multinomial model
plot.multinomial(combos)
## Convert to log scale to prevent underflow errors
post <- log(combos)
df.sub <- sim.inputs$df.sub
## Generate priors for each attribute
att.list <- unique(df.sub$Attribute)
wt <- .25 ## Note, we convolve informed prior with uniform prior. WT controls weight given to informed prior
p.vec <- data.frame(Attribute = att.list, p = NaN, stringsAsFactors = FALSE)
for (i in att.list){
p.vec$p[p.vec$Attribute == i]     <- gen.prior(post, filter(df.sub, Attribute == i), wt)
p.vec$p.bin[p.vec$Attribute == i] <- bin.probs(p.vec$p[p.vec$Attribute == i], bns)
}
## Plot priors
plot.priors(p.vec, n.seq)
p.est <- sim.inputs$p.est
p.est <- left_join(p.est %>% select(-p), p.vec, by = 'Attribute')
#ado.results <- run_ado(p.est, combos, post, bns, 'ADO')
rand.results <- lapply(1:10, function(x) run_ado(p.est, combos, post, bns, 'Random'))
grid.results <- lapply(1:10, function(x) run_ado(p.est, combos, post, bns, 'Grid'))
outcomes <- c()
outcomes[[1]] <- rand.results %>% bind_rows()
outcomes[[2]] <- grid.results %>% bind_rows
outcomes <- outcomes %>% bind_rows()
View(outcomes)
p <- ggplot(outcomes, aes(x = sim.round, y = Prob.Correct, color = method)) +
geom_line()
p
sim.seq <- rep(c('ADO', 'Random', 'Grid'), each = 10)
sim.seq
p.est <- sim.inputs$p.est
p.est <- left_join(p.est %>% select(-p), p.vec, by = 'Attribute')
sim.seq  <- rep(c('Random', 'Grid'), each = 5)
outcomes <- lapply(sim.seq, function(x) run_ado(p.est, combos, post, bns, x))
##plot.final(outcomes)
f1<-outcomes %>% bind_rows()
colnames(f1)
plot.final <- function(outcomes){
outcomes <- outcomes %>% bind_rows() %>%
group_by(sim.round, method) %>%
summarise(Prob.Correct = mean(Prob.Correct))
ggplot(outcomes, aes(x = sim.round, y = Prob.Correct, color = method)) +
geom_line() +
scale_x_continuous(name = 'Round') +
scale_y_continuous(labels = scales::percent, limits = c(.5, 1)) +
scale_color_brewer(palette = 'Set1') +
theme_bw()
}
plot.final(outcomes)
plot.final <- function(outcomes){
outcomes <- outcomes %>% bind_rows() %>%
group_by(sim.round, method) %>%
summarise(Prob.Correct = mean(Prob.Correct))
ggplot(outcomes, aes(x = sim.round, y = Prob.Correct, color = method)) +
geom_line() +
scale_x_continuous(name = 'Round') +
scale_y_continuous(labels = scales::percent, limits = c(.25, 1)) +
scale_color_brewer(palette = 'Set1') +
theme_bw()
}
plot.final(outcomes)
p.est <- sim.inputs$p.est
p.est <- left_join(p.est %>% select(-p), p.vec, by = 'Attribute')
sim.seq  <- rep(c('ADO', 'Random', 'Grid'), each = 5)
outcomes <- mclapply(sim.seq, function(x) run_ado(p.est, combos, post, bns, x))
plot.final(outcomes)
plot.final(outcomes)
rm(list=ls())
library(tidyr)
library(dplyr)
library(ggplot2)
library(matrixStats)
library(parallel)
library(viridis)
source('ado_funs.R')
output.dir <- 'outputs'
input.dir  <- 'inputs'
m.eps      <- .Machine$double.eps
sim.inputs <- readRDS(file.path(input.dir, 'SimulationInputs.RDS'))
## Load previously estimated thresholds of multinomial logistic regression
thresholds <- sim.inputs$thresholds
thresh     <- as.numeric(thresholds$Value)
## Using multinomial logistic regression model, compute probability of ratings 0 to 5 given latent values ranging from -4.5 to 4.5
n.seq <- seq(from = -4.5, to = 4.5, by = .05)
bns <- unlist(lapply(n.seq,
function(x) min(which(x <= c(thresh, Inf)))))
combos <- multi(n.seq, thresholds)
combos[combos == 0] <- m.eps
## Plot the multinomial model
plot.multinomial(combos)
## Convert to log scale to prevent underflow errors
post <- log(combos)
df.sub <- sim.inputs$df.sub
## Generate priors for each attribute
att.list <- unique(df.sub$Attribute)
wt <- .25 ## Note, we convolve informed prior with uniform prior. WT controls weight given to informed prior
p.vec <- data.frame(Attribute = att.list, p = NaN, stringsAsFactors = FALSE)
for (i in att.list){
p.vec$p[p.vec$Attribute == i]     <- gen.prior(post, filter(df.sub, Attribute == i), wt)
p.vec$p.bin[p.vec$Attribute == i] <- bin.probs(p.vec$p[p.vec$Attribute == i], bns)
}
## Plot priors
plot.priors(p.vec, n.seq)
p.est <- sim.inputs$p.est
p.est <- left_join(p.est %>% select(-p), p.vec, by = 'Attribute')
sim.seq  <- rep(c('ADO', 'Random', 'Grid'), each = 1)
outcomes <- mclapply(sim.seq, function(x) run_ado(p.est, combos, post, bns, x))
plot.final(outcomes)
